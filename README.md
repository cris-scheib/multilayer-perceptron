A multilayer perceptron is a neural network with more hidden layers
The idea behind the project was to learn the lower structures of neural networks behavior, so this project was made from scratch
The methods that were used are:
 - Sigmoid function for the neuron activations 
 - Stochastic Gradient Descent to optimize weights with the mean square error (MSE) function
 - Kahn's algorithm to sort the nodes to topological order
The dataset used on the project was from the [Mnist](http://yann.lecun.com/exdb/mnist/)
The project was based on the tensorflow structure, with model and the dense layer.=
