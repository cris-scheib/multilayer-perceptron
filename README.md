A multilayer perceptron is a neural network with more hidden layers
The idea behind the project was to learn the lower structures of neural networks behavior, so this project was made from scratch

The methods that were used on the Regression MLP are:
 - Sigmoid function for the neuron activations 
 - Stochastic Gradient Descent to optimize weights with the mean square error (MSE) function
 - Kahn's algorithm to sort the nodes to topological order

The methods that were used on the Classification MLP are:
 - Softmax function for the neuron activations 
 - Stochastic Gradient Descent to optimize weights with the cross entropy error function
 - Kahn's algorithm to sort the nodes to topological order
The dataset used on the project was from the [Mnist](http://yann.lecun.com/exdb/mnist/)

Both projects were based on the [Tensorflow Framework](https://www.tensorflow.org/) structure, with model and the dense layer and also on object-oriented programming.
